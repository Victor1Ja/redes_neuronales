{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31f5cad4",
   "metadata": {},
   "source": [
    "# Regresion Logistica con una Red Neuronal \n",
    "\n",
    "Bienvenidos al primer laboratorio, en el vamos a modelar una Regresion Logistica a travez de una red neurnal. Para ello, asumamos el siguiente problema: Dado un conjunto de datos :\n",
    "\n",
    "$$\\mathcal{D} = \\{X, Y\\} ~~~~~| ~~~x^{(i)} \\in \\mathcal{R}^{64\\times64}~~~,~~~ y^{(i)} \\in \\{0, 1\\}$$ \n",
    "\n",
    "Donde $x^{(i)}$ representa una imagen de 64 bits de alto y 64 bits de ancho e $y^{(i)}$ asume valor 1 si corresponde a una foto de un gato, y 0 en caso contrario.\n",
    "Debemos estimar para una imagen con estas dimensiones, si esta corresponde a un gato o no.\n",
    "\n",
    "Para comenzar debemos tener claro que tendremos a nuestra disposicion un conjunto de datos de entremaniento y un conjunto de datos de prueba, el de entrenamiento lo emplearemos para ajustar los parametros de la red nueronal de manera que alzance un nivel de generalizacion que permitan una vez terminado el entrenamiento, clasificar correctamente imagenes nuevas, es decir, las del conjunto de pueba.\n",
    "\n",
    "Carguemos los datos, asi como las librerias necesarias en nuestro código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be52234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "train_dataset = h5py.File('dataset/train_catvnoncat.h5', \"r\")\n",
    "train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # train set imagenes\n",
    "train_set_y = np.array(train_dataset[\"train_set_y\"][:]).reshape(train_set_x_orig.shape[0], 1) # train set etiquetas\n",
    "\n",
    "test_dataset = h5py.File('dataset/test_catvnoncat.h5', \"r\")\n",
    "test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # test set imagenes\n",
    "test_set_y = np.array(test_dataset[\"test_set_y\"][:]).reshape(test_set_x_orig.shape[0], 1) # test set etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f67d91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagenes de prueba: (50, 64, 64, 3)\n",
      "Imagenes de entrenamiento: (209, 64, 64, 3)\n",
      "Etiquetas de entrenamiento: (209, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Imagenes de prueba:', test_set_x_orig.shape)\n",
    "print('Imagenes de entrenamiento:', train_set_x_orig.shape)\n",
    "print('Etiquetas de entrenamiento:', train_set_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b682b2e6",
   "metadata": {},
   "source": [
    "Como pueden ver en la celda anterior, cada uno de los arreglos que contienenen las imagenes esta compuesto por una primera dimencion que representa la cantidad de ejemplos, en este caso de imagenes, las segundas y terceras son la cantidad de pixeles de ancho y largo (64x64), y finalmente la ultima la cantidad de canales que tiene la imagen, en este caso son 3 *RGB*.\n",
    "\n",
    "Para las etiquetas simplemente tenemos por cada ejemplo un valor asociado que puede ser 0 o 1. \n",
    "\n",
    "Con el siguiente celda podemos visualizar una imagen del conjunto de datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0285805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = [1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "index = 2\n",
    "plt.imshow(train_set_x_orig[index])\n",
    "print (f\"y = {train_set_y[index]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f776ed8",
   "metadata": {},
   "source": [
    "\n",
    "En la clase vimos que, para la neurona de nuestra red, su activación estaba dada como:\n",
    "$$\\hat{y} = \\sigma{(W^{T}X + b)}$$\n",
    "\n",
    "En esta expresion $X, W \\in \\mathcal{R}^{n}$. Sin embargo para nuestro problema, tenemos como entrada un objeto bidimensional, es decir $x^{(i)} \\in \\mathcal{R}^{64\\times64}$, para solventar esta situacion, y adaptar los datos a nuestro modelo, emplearemos la funcion reshape asociada los arreglos numpy\n",
    "\n",
    "```python\n",
    "X_flatten = X.reshape(X.shape[0], -1)    \n",
    "```\n",
    " \n",
    "convirtiendo nuestra imagen en un vector unidimensional donde cada componente representa un pixel de la imagen de manera que cada fila esta dispuesta una a continuacion de la otra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cf6c7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x_flatten shape: (209, 12288)\n",
      "train_set_y shape: (209, 1)\n",
      "test_set_x_flatten shape: (50, 12288)\n",
      "test_set_y shape: (50, 1)\n"
     ]
    }
   ],
   "source": [
    "### PROGRAME SU CODIGO AQUI ####\n",
    "\n",
    "train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0],-1)\n",
    "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0],-1)\n",
    "\n",
    "### FIN DE SU CODIGO ####\n",
    "\n",
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305f4314",
   "metadata": {},
   "source": [
    "**Salida Esperada**: \n",
    "\n",
    "<table style=\"width:35%\">\n",
    "  <tr>\n",
    "    <td>train_set_x_flatten shape</td>\n",
    "    <td> (209, 12288)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>train_set_y shape</td>\n",
    "    <td>(209, 1)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>test_set_x_flatten shape</td>\n",
    "    <td>(50, 12288)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>test_set_y shape</td>\n",
    "    <td>(50, 1)</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975640cc",
   "metadata": {},
   "source": [
    "Para representar imágenes en color, hay que especificar los canales rojo, verde y azul (RGB) para cada píxel, por lo que el valor del píxel es en realidad un vector de tres números que van de 0 a 255.\n",
    "\n",
    "Un paso común de preprocesamiento en el aprendizaje automático es centrar y estandarizar tu conjunto de datos, lo que significa que restas la media de todo el arreglo cada ejemplo, y luego divides cada ejemplo por la desviación estándar. Pero para los conjuntos de datos de imágenes, es más simple y más conveniente y funciona casi igual de bien simplemente dividir cada fila del conjunto de datos por 255 (el valor máximo de un canal de píxeles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "516c7329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06666667 0.12156863 0.21960784 ... 0.         0.         0.        ]\n",
      " [0.76862745 0.75294118 0.74509804 ... 0.32156863 0.31372549 0.31764706]\n",
      " [0.32156863 0.27843137 0.26666667 ... 0.54117647 0.55294118 0.55686275]\n",
      " ...\n",
      " [0.56078431 0.60784314 0.64705882 ... 0.33333333 0.41960784 0.58431373]\n",
      " [0.08627451 0.09411765 0.09019608 ... 0.01568627 0.01960784 0.        ]\n",
      " [0.03137255 0.10980392 0.20784314 ... 0.         0.         0.        ]]\n",
      "[[0.61960784 0.40784314 0.3254902  ... 0.67843137 0.50196078 0.43137255]\n",
      " [0.45098039 0.43137255 0.43529412 ... 0.67058824 0.69019608 0.72941176]\n",
      " [1.         0.99215686 0.99607843 ... 0.52156863 0.39607843 0.4745098 ]\n",
      " ...\n",
      " [0.16078431 0.18431373 0.32941176 ... 0.71764706 0.55294118 0.45490196]\n",
      " [0.07058824 0.07058824 0.0627451  ... 0.56470588 0.5372549  0.42352941]\n",
      " [0.52156863 0.63921569 0.29411765 ... 0.01960784 0.08627451 0.01960784]]\n"
     ]
    }
   ],
   "source": [
    "### PROGRAME AQUI ###\n",
    "train_set_x_flatten = train_set_x_flatten/255.0\n",
    "test_set_x_flatten = test_set_x_flatten/255.0\n",
    "### FIN DE SU CODIGO ###\n",
    "print(train_set_x_flatten)\n",
    "print(test_set_x_flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044d605c",
   "metadata": {},
   "source": [
    "\n",
    "### Hasta el momento que deber recordar:\n",
    "\n",
    "    \n",
    "Los pasos habituales para el preprocesamiento de un nuevo conjunto de datos son:\n",
    "\n",
    "- Averiguar las dimensiones y formas del problema (m_train, m_test, num_px, ...)\n",
    "- Reformar los conjuntos de datos de manera que cada ejemplo sea ahora un vector de tamaño (1, num_px \\* num_px \\* 3)\n",
    "- Estandarizar los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434a93c2",
   "metadata": {},
   "source": [
    "## Arquitectura General\n",
    "\n",
    "\n",
    "Es hora de diseñar un algoritmo sencillo para distinguir las imágenes de gatos de las que no lo son..\n",
    "\n",
    "**Expresiones matematicas que debes tener en cuenta**:\n",
    "\n",
    "Para un ejemplo $x^{(i)}$, donde i representa el indice de dicho ejemplo:\n",
    "\n",
    "\n",
    "$$z^{(i)} = w^T x^{(i)} + b \\tag{1}$$\n",
    "$$\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\\tag{2}$$ \n",
    "$$ \\mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(a^{(i)}) - (1-y^{(i)} )  \\log(1-a^{(i)})\\tag{3}$$\n",
    "\n",
    "\n",
    "El costo es calculado por la suma sobre el error o perdida de todos los ejemplos:\n",
    "\n",
    "$$ C = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})\\tag{6}$$\n",
    "\n",
    "**Aspectos Claves**:\n",
    "    \n",
    "En este ejercicio, realizarás los siguientes pasos: \n",
    "\n",
    "- Inicializar los parámetros del modelo.\n",
    "- Aprender los parámetros del modelo minimizando el costo **C**.  \n",
    "- Utilizar los parámetros aprendidos para hacer predicciones (en el conjunto de pruebas).\n",
    "- Analizar los resultados y concluir\n",
    "\n",
    "\n",
    "Los principales pasos para construir una red neuronal son:\n",
    "\n",
    "1. Definir la estructura del modelo (como el número de características de entrada) \n",
    "2. Inicializar los parámetros del modelo\n",
    "3. Bucle:\n",
    "    - Calcular la pérdida de corriente (propagación hacia delante)\n",
    "    - Calcular el gradiente actual (propagación hacia atrás)\n",
    "    - Actualizar los parámetros (descenso de gradiente)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fffcce",
   "metadata": {},
   "source": [
    "**Ejercicio**: Implementa una funcion `sigmoid()`, que reciba como parametro un escalar o un arreglo numpy. Como has visto, necesitas calcular $sigmoide( w^T x + b) = \\frac{1}{1 + e^{-(w^T x + b)}}$ para hacer predicciones. Utilice \n",
    "```python\n",
    "np.exp()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a4f6a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### PONGA SU CODIGO AQUI ###\n",
    "    s = 1./(1+np.exp(-z))\n",
    "    ### FIN DE SU CODIGO\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2be30357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid([0, 2]) = [0.5        0.88079708]\n"
     ]
    }
   ],
   "source": [
    "print (\"sigmoid([0, 2]) = \" + str(sigmoid(np.array([0,2]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd56d30",
   "metadata": {},
   "source": [
    "**Salida esperada**\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>sigmoid([0, 2])</td>\n",
    "    <td> [ 0.5         0.88079708]</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a69374",
   "metadata": {},
   "source": [
    "### Initializing parameters\n",
    "\n",
    "**Ejercicio:** Implementa la inicialización de los parámetros en la celda de abajo. Tienes que inicializar w como un vector de ceros. Si no sabes qué función de numpy usar, busca np.zeros() en la documentación de la biblioteca Numpy.\n",
    "\n",
    "Aqui vamos a inicializar en 0, porque a pesar de que lo usual es inicializar random como quedamos en la conferencia, Nos evitaremos el no determinismo que acarrea ejecutar una celda varias veces, teninedo en cuenta que la funcion de coste es concava.\n",
    "\n",
    "**Lo que pasaba ayer que np.random.seed() no permitia obtener el mismo resultado cada vez, es que el kernel de python sobre el cual corre jupyter no para caundo se ejecuta una celda, si no que sigue ejecutandose, esto permite que podamos acceder a variables de una celda desde otra, por lo que correr x = np.random.randn() varias veces seria equivalente a generar tantos numeros aleatorios como las veces que corramos la celda. Puedes correr en un terminal si estas en linux la siguiente linea de comando tantas veces como quieras y en ese caso si obtendras el mismo resultado, ya que el codigo de python corre y luego se detiene:**\n",
    "\n",
    "```bash\n",
    "python -c 'import numpy as np; np.random.seed(3);print(np.random.randn())'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c05dc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    Esta funcion crea un vector de ceros de dimension (dim, 1) para w e inicializa b en 0.\n",
    "    \n",
    "    Argument:\n",
    "    dim -- el tamaño del vector w (o numero de parametros en nuestro caso, recuerden que w <w1,w2,w3>)\n",
    "    \n",
    "    Returns:\n",
    "    w -- un 0-vector de la forma (dim, 1)\n",
    "    b -- un escalar (correspondiente al termino de sesgo)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    w = np.zeros((dim,1))\n",
    "    b = 0\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    assert(w.shape == (dim, 1))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb8f813b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [[0.]\n",
      " [0.]]\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "dim = 2\n",
    "w, b = initialize_with_zeros(dim)\n",
    "print (\"w = \" + str(w))\n",
    "print (\"b = \" + str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be18f4df",
   "metadata": {},
   "source": [
    "**Salida Esperada**: \n",
    "​\n",
    "​\n",
    "<table style=\"width:15%\">\n",
    "    <tr>\n",
    "        <td>  w   </td>\n",
    "        <td> [[ 0.]\n",
    "              [ 0.]] </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>   b  </td>\n",
    "        <td> 0 </td>\n",
    "    </tr>\n",
    "</table>\n",
    "​\n",
    "Para la entrada que tenemos, w tendra la forma (num_px $\\times$ num_px $\\times$ 3, 1), es decir nuestra neurona, o  nuestra funcion de aproximacion tendra num_px $\\times$ num_px $\\times$ 3 parametros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a6d606",
   "metadata": {},
   "source": [
    "### Forward and Backward propagation\n",
    "\n",
    "Ahora que todos los parametros estan inicializados pordemos hacer la propagacion hacia adelante y hacia atras para el aprendizaje de los parametros.\n",
    "\n",
    "**Hints**:\n",
    "\n",
    "Primero recordar que la notacion $X^{(i)}$ se refiere al $i-esimo$ ejemplo de la imagen en su forma plana, que calculamos usando la funcion reshape.\n",
    "\n",
    "Forward Propagation:\n",
    "- Tenemos X\n",
    "- Calculamos a $A = \\sigma(w^T X^{(i)} + b) = (a^{(1)}, a^{(2)}, ..., a^{(m-1)}, a^{(m)})$\n",
    "- Calculamos la funcion de costo como: $J = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})$\n",
    "\n",
    "Aqui hay dos formulas que usaremos: \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{8}$$\n",
    "\n",
    "y \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w_{k}} = \\frac{1}{m} \\sum_{i=1}^m x_{k}^{(i)}(a^{(i)}-y^{(i)})\\tag{9}$$\n",
    "\n",
    "Fijate que estamos hablando de la componente $k-esima$ del vector de entrada $X^{(i)}$ y de los parametros $w$. Lo cual en forma matricial puede ser expresado como\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T\\tag{9.1}$$\n",
    "\n",
    "Numpy para sus arreglos tiene implementado lo que es conocido como el broadcasting y es ideal para el uso de vectorizacion.\n",
    "- El brodacasting no es mas que la extension que realiza numpy a efectuar operaciones entre arreglos numpy en sobre eje, siempre que el resto de los ejes (dimesiones) matchee, por ejemplo:\n",
    "\n",
    "$$\\begin{bmatrix} a_{1} \\\\ a_{2} \\\\ a_{3}  \\end{bmatrix} + [b] \\implies \\begin{bmatrix} a_{1} \\\\ a_{2} \\\\ a_{3}  \\end{bmatrix} + \\begin{bmatrix} b \\\\ b \\\\ b  \\end{bmatrix} = \\begin{bmatrix} a_{1}+b \\\\ a_{2}+b \\\\ a_{3} +b \\end{bmatrix}$$\n",
    "\n",
    "- La vectoriazacion no es mas que tratar la operacion de producto de varios elementos y su suma como una operacion de productos de matrices. Esto es fundamental para la paralelizacion de las operaciones de las cuales nnumpy se aprovecha. Por ejemplo:\n",
    "\n",
    "$$w_{1}x_{1}+w_{2}x_{2} + w_{3}x_{3} + w_{4}x_{4} = \\begin{bmatrix} w_{1} \\\\ w_{2} \\\\ w_{3}  \\end{bmatrix}^{T}*\\begin{bmatrix} x_{1} \\\\ x_{2} \\\\ x_{3}  \\end{bmatrix} = \\begin{bmatrix} w_{1}&w_{2}&w_{3}  \\end{bmatrix}\\begin{bmatrix} x_{1} \\\\ x_{2} \\\\ x_{3}  \\end{bmatrix} = w^{T}*X$$\n",
    "\n",
    "     En el caso que nos ocupa, X para cada fila contiene un ejemplo, una manera simplificado de esbozar este ejemplo, dado \n",
    "\n",
    "\n",
    "$$X = \\begin{bmatrix} x_{1}^{(1)} & x_{1}^{(2)} & x_{1}^{(3)} \\\\ x_{2}^{(1)} & x_{2}^{(2)} & x_{2}^{(3)} \\\\ x_{3}^{(1)} & x_{3}^{(1)} & x_{3}^{(1)} \\end{bmatrix}$$\n",
    "\n",
    "\n",
    "    Luego:\n",
    "\n",
    "$$w^{T}*X = \\begin{bmatrix} w_{1}&w_{2}&w_{3}  \\end{bmatrix}\\begin{bmatrix} x_{1}^{(1)} & x_{1}^{(2)} & x_{1}^{(3)} \\\\ x_{2}^{(1)} & x_{2}^{(2)} & x_{2}^{(3)} \\\\ x_{3}^{(1)} & x_{3}^{(1)} & x_{3}^{(1)} \\end{bmatrix} = \\begin{bmatrix} a^{(1)} & a^{(2)} & a^{(3)}  \\end{bmatrix}$$\n",
    "\n",
    "Por lo que seria conveniente que nuestro arrego de datos de entrada tuvieran la forma $(num_px * num_px * 3,~ numero~de~ejemplos)$ y para calcular el gradiente el vector de la etiqueta de los ejemplos tenga la forma $(1,~ numero~de~ejemplos)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba38ed5",
   "metadata": {},
   "source": [
    "**Ejercicio:** emplee la propiedad transpuesta de los arreglos numpy para que los datos de entrada de test y train tengan la forma $(num_px * num_px * 3,~ numero~de~ejemplo)$\n",
    "\n",
    "```python\n",
    "X.T # devuelve la transpuesta de la matriz T\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec7b6a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x_flatten shape: (12288, 209)\n",
      "train_set_y shape: (1, 209)\n",
      "test_set_x_flatten shape: (12288, 50)\n",
      "test_set_y shape: (1, 50)\n"
     ]
    }
   ],
   "source": [
    "### PROGRAME AQUI ###\n",
    "train_set_x_flatten = train_set_x_flatten.T\n",
    "train_set_y = train_set_y.T\n",
    "test_set_x_flatten = test_set_x_flatten.T\n",
    "test_set_y = test_set_y.T\n",
    "### FIN DE SU CODIGO ###\n",
    "\n",
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9fc206",
   "metadata": {},
   "source": [
    "**Salida Esperada**: \n",
    "\n",
    "<table style=\"width:35%\">\n",
    "  <tr>\n",
    "    <td>train_set_x_flatten shape</td>\n",
    "    <td> (12288, 209)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>train_set_y shape</td>\n",
    "    <td>(1, 209)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>test_set_x_flatten shape</td>\n",
    "    <td>(12288, 50)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>test_set_y shape</td>\n",
    "    <td>(1, 50)</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca10770b",
   "metadata": {},
   "source": [
    "**Ejercicio:** Implemente la funcion `propagate()` que calcula la funcion de costo y sus gradientes, haciendo uso del broadcasting y la vectorizacion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9642c2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Implementa la funcion de costo y sus gradientes para la propagacion explicada arriba\n",
    "\n",
    "    Arguments:\n",
    "    w -- pesos de los parametros, un arreglo numpy de la forma (num_px * num_px * 3, 1)\n",
    "    b -- bias, un scalar\n",
    "    X -- conjunto de datos (num_px * num_px * 3, numero de ejemplos)\n",
    "    Y -- vector de etiquetas (conteniendo 0 si non-cat, 1 si cat) de la forma (1, numero de ejemplos)\n",
    "\n",
    "    Return:\n",
    "    cost -- el opuesto de la probabilidad log para la regresion logisitca\n",
    "    dw -- gradiente de la perdida con respecto a w, por tanto tine la misma shape de w\n",
    "    db -- gradiente de la perdida con respecto a b, por tanto tine la misma shape de b\n",
    "    \n",
    "    Tips:\n",
    "    - np.log() calcula logaritmo de escalar o arreglo numpy, np.dot() calcula el producto matricial de dos arreglos numpy\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # FORWARD PROPAGATION (FROM X TO COST)\n",
    "    ### PROGRAMA AQUI ###\n",
    "    A = sigmoid(np.dot(w.T,X) +b)                                   # compute activation\n",
    "    #cost = -(np.dot(Y, np.log(A.T)) + np.dot(1. - Y, np.log(1. - A.T)))/m\n",
    "    cost = 0\n",
    "    for i in range(m):\n",
    "        cost = cost+ (Y[0][i])*np.log(A[0][i]) + (1. - Y[0][i])*np.log(1. - A[0][i])\n",
    "\n",
    "    cost = -(cost)/m\n",
    "    # compute cost\n",
    "    ### FIN DEL CODE ###\n",
    "    \n",
    "    # BACKWARD PROPAGATION (TO FIND GRAD)\n",
    "    ### PROGRAMA AQUI ### \n",
    "    db = A - Y\n",
    "    dw = (np.dot(X,db.T))/m\n",
    "    db = np.sum(db)/m\n",
    "    ### FIN DEL CODE ###\n",
    "\n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d8a589b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw = [[0.99845601]\n",
      " [2.39507239]]\n",
      "db = 0.001455578136784208\n",
      "cost = 5.801545319394553\n"
     ]
    }
   ],
   "source": [
    "w, b, X, Y = np.array([[1.],[2.]]), 2., np.array([[1.,2.,-1.],[3.,4.,-3.2]]), np.array([[1,0,1]])\n",
    "grads, cost = propagate(w, b, X, Y)\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print (\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a66645",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table style=\"width:50%\">\n",
    "    <tr>\n",
    "        <td>  dw  </td>\n",
    "      <td> [[ 0.99845601]\n",
    "     [ 2.39507239]]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  db  </td>\n",
    "        <td> 0.00145557813678 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  cost </td>\n",
    "        <td> 5.801545319394553 </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cc9242",
   "metadata": {},
   "source": [
    "### Optimizacion\n",
    "\n",
    "- Has inicializado tus parámetros.\n",
    "- También eres capaz de calcular una función de coste y su gradiente.\n",
    "- Ahora, quieres actualizar los parámetros utilizando el descenso de gradiente.\n",
    "\n",
    "**Ejercicio:** Escriba la función de optimización. El objetivo es aprender $w$ y $b$ minimizando la función de coste $C$. Para un parámetro $\\theta$, la regla de actualización es $ \\theta = \\theta - \\alpha \\text{ } d\\theta$, donde $\\alpha$ es la tasa de aprendizaje (learning rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18897598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    Esta función optimiza w y b ejecutando un algoritmo de descenso de gradiente\n",
    "    \n",
    "    Arguments:\n",
    "    w -- pesos, un array numpy de tamaño (num_px * num_px * 3, 1)\n",
    "    b -- bias, un escalar\n",
    "    X -- datos de forma (num_px * num_px * 3, número de ejemplos)\n",
    "    Y -- vector de etiquetas (que contiene 0 si no es gato, 1 si es gato), de forma (número de ejemplos, 1)\n",
    "    num_iterations -- número de iteraciones del bucle de optimización\n",
    "    learning_rate -- tasa de aprendizaje de la regla de actualización del descenso de gradiente\n",
    "    print_cost -- bool que en Verdadero permite imprimir la pérdida cada 100 iteraciones del algoritmo del descenso del graiente\n",
    "    \n",
    "    Return:\n",
    "    params -- diccionario que contiene los pesos w y el sesgo b\n",
    "    grads -- diccionario que contiene los gradientes de los pesos y el bias con respecto a la función de coste\n",
    "    costs -- lista de todos los costes calculados durante la optimización, que se utilizará para trazar la curva de aprendizaje.\n",
    "    \n",
    "    Consejos:\n",
    "    Básicamente necesitas escribir dos pasos e iterar a través de ellos:\n",
    "        1) Calcular el coste y el gradiente para los parámetros actuales. Use propagate().\n",
    "        2) Actualizar los parámetros utilizando la regla de descenso de gradiente para w y b.\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        \n",
    "        # Calculo del Costo y el gradiente\n",
    "        ### PROGRAMA AQUI ### \n",
    "        grads, cost = propagate(w,b,X,Y)\n",
    "        ### FIN DEL CODIGO ###\n",
    "        \n",
    "        # Obten las derivadas de grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # Regla de actualizacion del descenso del gradiente\n",
    "        ### PROGRAMA AQUI ### \n",
    "        w = w - dw*learning_rate\n",
    "        b = b - db*learning_rate\n",
    "        ### FIN DEL CODIGO ###\n",
    "        \n",
    "        # guarda los costos\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        # Imprimir el costo cada 100 iteraciones\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "420a4632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [[0.19033591]\n",
      " [0.12259159]]\n",
      "b = 1.9253598300845747\n",
      "dw = [[0.67752042]\n",
      " [1.41625495]]\n",
      "db = 0.21919450454067657\n",
      "[[1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "params, grads, costs = optimize(w, b, X, Y, num_iterations= 100, learning_rate = 0.009, print_cost = False)\n",
    "\n",
    "print (\"w = \" + str(params[\"w\"]))\n",
    "print (\"b = \" + str(params[\"b\"]))\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print (Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bdb6e9",
   "metadata": {},
   "source": [
    "**Salida Esperada**: \n",
    "\n",
    "<table >\n",
    "<tr>\n",
    "<td> w </td>\n",
    "<td>[[ 0.19033591]\n",
    "[ 0.12259159]] </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td> b </td>\n",
    "<td> 1.92535983008 </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td> dw </td>\n",
    "<td> [[ 0.67752042]\n",
    "[ 1.41625495]] </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td> **db** </td>\n",
    "<td> 0.219194504541 </td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923dbb2c",
   "metadata": {},
   "source": [
    "\n",
    "**Exercise:** The previous function will output the learned w and b. We are able to use w and b to predict the labels for a dataset X. Implement the `predict()` function. There are two steps to computing predictions:\n",
    "\n",
    "1. Calculate $\\hat{Y} = A = \\sigma(w^T X + b)$\n",
    "\n",
    "2. Convert the entries of a into 0 (if activation <= 0.5) or 1 (if activation > 0.5), stores the predictions in a vector `Y_prediction`. If you wish, you can use an `if`/`else` statement in a `for` loop (though there is also a way to vectorize this). \n",
    "\n",
    "**Ejercicio:**\n",
    "\n",
    "La función anterior dará como resultado los valores aprendidos w y b. Podemos utilizar w y b para predecir las etiquetas de un conjunto de datos X. Implementa la función `predict()`.\n",
    "\n",
    "Hay dos pasos para calcular las predicciones:\n",
    "\n",
    "1. Calcular $\\hat{Y} = A = \\sigma(w^T X + b)$\n",
    "\n",
    "2. Convertir los valores de a en 0 (si la activación <= 0,5) o 1 (si la activación > 0,5). Ya que recuerda que un valor de probabilidad, almacena las predicciones en un vector `Y_predicción`. Si lo deseas, puedes utilizar una sentencia `if`/`else` en un bucle `for` (aunque también hay una forma de vectorizar esto). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48ec9d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    '''\n",
    "    \n",
    "    Predecir si la etiqueta es 0 o 1 utilizando los parámetros de regresión logística aprendidos (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- pesos, una matriz numpy de tamaño (num_px * num_px * 3, 1)\n",
    "    b -- sesgo, un escalar\n",
    "    X -- datos de tamaño (num_px * num_px * 3, número de ejemplos)\n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- un arreglo numpy (vector) que contiene todas las predicciones (0/1) para los ejemplos en X\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    # calcular el vector \"A\" que predice las probabilidades de que haya un gato en la imagen\n",
    "    ### PROGRAMA AQUI ### \n",
    "    A= sigmoid(np.dot(w.T,X) + b )\n",
    "    ### FIN DEL CODE ###\n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        \n",
    "        # Convertir las probabilidades A[0,i] en predicciones reales p[0,i]\n",
    "        ### PROGRAMA AQUI ### \n",
    "        if A[0][i] >0.5:\n",
    "            Y_prediction[0][i] = 1\n",
    "        ### FIN DEL CODE ###\n",
    "    \n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08d4acc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions = [[1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "w = np.array([[0.1124579],[0.23106775]])\n",
    "b = -0.3\n",
    "X = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\n",
    "print (\"predictions = \" + str(predict(w, b, X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4f2bbb",
   "metadata": {},
   "source": [
    "**Salida esperada**: \n",
    "\n",
    "<table style=\"width:30%\">\n",
    "    <tr>\n",
    "         <td>\n",
    "             predictions\n",
    "         </td>\n",
    "          <td>\n",
    "            [[ 1.  1.  0.]]\n",
    "         </td>  \n",
    "   </tr>\n",
    "\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae9e69a",
   "metadata": {},
   "source": [
    "\n",
    "### Hasta el momento que deber recordar:\n",
    "\n",
    "\n",
    "Has implementado varias funciones que:\n",
    "    \n",
    "- Inicializan (w,b)\n",
    "\n",
    "- Optimizan la pérdida iterativamente para aprender los parámetros (w,b):\n",
    "    - calcular el coste y su gradiente \n",
    "    - actualizar los parámetros mediante el descenso de gradiente\n",
    "- Utilizar los parámetros aprendidos (w,b) para predecir las etiquetas de un conjunto dado de ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b636122",
   "metadata": {},
   "source": [
    "## Uniendo las funcinoes en nuestro modelo ##\n",
    "\n",
    "\n",
    "Ahora verás cómo está estructurado el modelo global al juntar todos los bloques (funciones implementadas en las partes anteriores), en el orden correcto.\n",
    "\n",
    "**Ejercicio:**\n",
    "\n",
    "Implementar la función del modelo. Utilice la siguiente notación:\n",
    "- Y_prediction_test para tus predicciones en el conjunto de prueba\n",
    "- Y_prediction_train para tus predicciones en el conjunto de entrenamiento\n",
    "- w, costs, grads para las salidas de optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36c0a6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n",
    "    \"\"\"\n",
    "    \n",
    "    Construye el modelo de regresión logística llamando a las funciónes que has implementado previamente\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- conjunto de entrenamiento representado por una matriz numpy de forma (num_px * num_px * 3, m_train)\n",
    "    Y_train -- etiquetas de entrenamiento representadas por un arreglo numpy (vector) de forma (1, m_train)\n",
    "    X_test -- conjunto de pruebas representado por un arreglo  numpy de forma (num_px * num_px * 3, m_test)\n",
    "    Y_test -- etiquetas de prueba representadas por un arreglo  numpy (vector) de forma (1, m_test)\n",
    "    num_iterations -- hiperparámetro que representa el número de iteraciones para optimizar los parámetros\n",
    "    learning_rate -- hiperparámetro que representa la tasa de aprendizaje utilizada en la regla de actualización de optimize()\n",
    "    print_cost -- Se establece en true para imprimir el coste cada 100 iteraciones\n",
    "    \n",
    "    Returns:\n",
    "    d -- diccionario que contiene información sobre el modelo.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### PROGRAMA AQUI ###\n",
    "    \n",
    "    # Inicializa los parametros con 0\n",
    "    w, b = initialize_with_zeros(12288)\n",
    "    print(str(w.shape))\n",
    "    print(str(X_train.shape))\n",
    "\n",
    "    # Gradient descent \n",
    "    parameters, grads, costs = optimize(w,b,X_train,Y_train,num_iterations,learning_rate)\n",
    "    \n",
    "    # Obten los parametros w y b del diccionario \"parameters\"\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    # Predecir ejemplos del conjunto de test/train\n",
    "    print(\"w:\" + str(w.shape))\n",
    "    Y_prediction_test = predict( w , b , X_test )\n",
    "    Y_prediction_train = predict( w , b , X_train )\n",
    "\n",
    "    ### FIN DEL CODE ###\n",
    "\n",
    "    # Imprime Error del train/test\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95883521",
   "metadata": {},
   "source": [
    "## Con la siguiente celda entrenaremos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edcb9414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12288, 1)\n",
      "(12288, 209)\n",
      "w:(12288, 1)\n",
      "train accuracy: 99.04306220095694 %\n",
      "test accuracy: 70.0 %\n"
     ]
    }
   ],
   "source": [
    "history = model(train_set_x_flatten, train_set_y, test_set_x_flatten, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4e1473",
   "metadata": {},
   "source": [
    "**Comentario:**\n",
    "\n",
    "La precisión del entrenamiento se acerca al 100%. Esto es una buena comprobación de cordura: su modelo está funcionando y tiene suficiente capacidad para ajustarse a los datos de entrenamiento. El error de prueba es del 70%. En realidad no está mal para este sencillo modelo, dado el pequeño conjunto de datos que utilizamos y que la regresión logística es un clasificador lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92a5eaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curve (with costs)\n",
    "costs = np.squeeze(history['costs'])\n",
    "plt.plot(costs)\n",
    "plt.ylabel('Costo')\n",
    "plt.xlabel('Iteraciones (x100)')\n",
    "plt.title(\"Learning rate =\" + str(history[\"learning_rate\"]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
