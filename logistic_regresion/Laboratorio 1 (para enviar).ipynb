{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31f5cad4",
   "metadata": {},
   "source": [
    "# Regresion Logistica con una Red Neuronal \n",
    "\n",
    "Bienvenidos al primer laboratorio, en el vamos a modelar una Regresion Logistica a travez de una red neurnal. Para ello, asumamos el siguiente problema: Dado un conjunto de datos :\n",
    "\n",
    "$$\\mathcal{D} = \\{X, Y\\} ~~~~~| ~~~x^{(i)} \\in \\mathcal{R}^{64\\times64}~~~,~~~ y^{(i)} \\in \\{0, 1\\}$$ \n",
    "\n",
    "Donde $x^{(i)}$ representa una imagen de 64 bits de alto y 64 bits de ancho e $y^{(i)}$ asume valor 1 si corresponde a una foto de un gato, y 0 en caso contrario.\n",
    "Debemos estimar para una imagen con estas dimensiones, si esta corresponde a un gato o no.\n",
    "\n",
    "Para comenzar debemos tener claro que tendremos a nuestra disposicion un conjunto de datos de entremaniento y un conjunto de datos de prueba, el de entrenamiento lo emplearemos para ajustar los parametros de la red nueronal de manera que alzance un nivel de generalizacion que permitan una vez terminado el entrenamiento, clasificar correctamente imagenes nuevas, es decir, las del conjunto de pueba.\n",
    "\n",
    "Carguemos los datos, asi como las librerias necesarias en nuestro c√≥digo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be52234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "train_dataset = h5py.File('dataset/train_catvnoncat.h5', \"r\")\n",
    "train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # train set imagenes\n",
    "train_set_y = np.array(train_dataset[\"train_set_y\"][:]).reshape(train_set_x_orig.shape[0], 1) # train set etiquetas\n",
    "\n",
    "test_dataset = h5py.File('dataset/test_catvnoncat.h5', \"r\")\n",
    "test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # test set imagenes\n",
    "test_set_y = np.array(test_dataset[\"test_set_y\"][:]).reshape(test_set_x_orig.shape[0], 1) # test set etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f67d91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagenes de prueba: (50, 64, 64, 3)\n",
      "Imagenes de entrenamiento: (209, 64, 64, 3)\n",
      "Etiquetas de entrenamiento: (209, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Imagenes de prueba:', test_set_x_orig.shape)\n",
    "print('Imagenes de entrenamiento:', train_set_x_orig.shape)\n",
    "print('Etiquetas de entrenamiento:', train_set_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b682b2e6",
   "metadata": {},
   "source": [
    "Como pueden ver en la celda anterior, cada uno de los arreglos que contienenen las imagenes esta compuesto por una primera dimencion que representa la cantidad de ejemplos, en este caso de imagenes, las segundas y terceras son la cantidad de pixeles de ancho y largo (64x64), y finalmente la ultima la cantidad de canales que tiene la imagen, en este caso son 3 *RGB*.\n",
    "\n",
    "Para las etiquetas simplemente tenemos por cada ejemplo un valor asociado que puede ser 0 o 1. \n",
    "\n",
    "Con el siguiente celda podemos visualizar una imagen del conjunto de datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0285805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = [1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "index = 2\n",
    "plt.imshow(train_set_x_orig[index])\n",
    "print (f\"y = {train_set_y[index]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f776ed8",
   "metadata": {},
   "source": [
    "\n",
    "En la clase vimos que, para la neurona de nuestra red, su activaci√≥n estaba dada como:\n",
    "$$\\hat{y} = \\sigma{(W^{T}X + b)}$$\n",
    "\n",
    "En esta expresion $X, W \\in \\mathcal{R}^{n}$. Sin embargo para nuestro problema, tenemos como entrada un objeto bidimensional, es decir $x^{(i)} \\in \\mathcal{R}^{64\\times64}$, para solventar esta situacion, y adaptar los datos a nuestro modelo, emplearemos la funcion reshape asociada los arreglos numpy\n",
    "\n",
    "```python\n",
    "X_flatten = X.reshape(X.shape[0], -1)    \n",
    "```\n",
    " \n",
    "convirtiendo nuestra imagen en un vector unidimensional donde cada componente representa un pixel de la imagen de manera que cada fila esta dispuesta una a continuacion de la otra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cf6c7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x_flatten shape: (209, 12288)\n",
      "train_set_y shape: (209, 1)\n",
      "test_set_x_flatten shape: (50, 12288)\n",
      "test_set_y shape: (50, 1)\n"
     ]
    }
   ],
   "source": [
    "### PROGRAME SU CODIGO AQUI ####\n",
    "\n",
    "train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0],-1)\n",
    "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0],-1)\n",
    "\n",
    "### FIN DE SU CODIGO ####\n",
    "\n",
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305f4314",
   "metadata": {},
   "source": [
    "**Salida Esperada**: \n",
    "\n",
    "<table style=\"width:35%\">\n",
    "  <tr>\n",
    "    <td>train_set_x_flatten shape</td>\n",
    "    <td> (209, 12288)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>train_set_y shape</td>\n",
    "    <td>(209, 1)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>test_set_x_flatten shape</td>\n",
    "    <td>(50, 12288)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>test_set_y shape</td>\n",
    "    <td>(50, 1)</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975640cc",
   "metadata": {},
   "source": [
    "Para representar im√°genes en color, hay que especificar los canales rojo, verde y azul (RGB) para cada p√≠xel, por lo que el valor del p√≠xel es en realidad un vector de tres n√∫meros que van de 0 a 255.\n",
    "\n",
    "Un paso com√∫n de preprocesamiento en el aprendizaje autom√°tico es centrar y estandarizar tu conjunto de datos, lo que significa que restas la media de todo el arreglo cada ejemplo, y luego divides cada ejemplo por la desviaci√≥n est√°ndar. Pero para los conjuntos de datos de im√°genes, es m√°s simple y m√°s conveniente y funciona casi igual de bien simplemente dividir cada fila del conjunto de datos por 255 (el valor m√°ximo de un canal de p√≠xeles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "516c7329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06666667 0.12156863 0.21960784 ... 0.         0.         0.        ]\n",
      " [0.76862745 0.75294118 0.74509804 ... 0.32156863 0.31372549 0.31764706]\n",
      " [0.32156863 0.27843137 0.26666667 ... 0.54117647 0.55294118 0.55686275]\n",
      " ...\n",
      " [0.56078431 0.60784314 0.64705882 ... 0.33333333 0.41960784 0.58431373]\n",
      " [0.08627451 0.09411765 0.09019608 ... 0.01568627 0.01960784 0.        ]\n",
      " [0.03137255 0.10980392 0.20784314 ... 0.         0.         0.        ]]\n",
      "[[0.61960784 0.40784314 0.3254902  ... 0.67843137 0.50196078 0.43137255]\n",
      " [0.45098039 0.43137255 0.43529412 ... 0.67058824 0.69019608 0.72941176]\n",
      " [1.         0.99215686 0.99607843 ... 0.52156863 0.39607843 0.4745098 ]\n",
      " ...\n",
      " [0.16078431 0.18431373 0.32941176 ... 0.71764706 0.55294118 0.45490196]\n",
      " [0.07058824 0.07058824 0.0627451  ... 0.56470588 0.5372549  0.42352941]\n",
      " [0.52156863 0.63921569 0.29411765 ... 0.01960784 0.08627451 0.01960784]]\n"
     ]
    }
   ],
   "source": [
    "### PROGRAME AQUI ###\n",
    "train_set_x_flatten = train_set_x_flatten/255.0\n",
    "test_set_x_flatten = test_set_x_flatten/255.0\n",
    "### FIN DE SU CODIGO ###\n",
    "print(train_set_x_flatten)\n",
    "print(test_set_x_flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044d605c",
   "metadata": {},
   "source": [
    "\n",
    "### Hasta el momento que deber recordar:\n",
    "\n",
    "    \n",
    "Los pasos habituales para el preprocesamiento de un nuevo conjunto de datos son:\n",
    "\n",
    "- Averiguar las dimensiones y formas del problema (m_train, m_test, num_px, ...)\n",
    "- Reformar los conjuntos de datos de manera que cada ejemplo sea ahora un vector de tama√±o (1, num_px \\* num_px \\* 3)\n",
    "- Estandarizar los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434a93c2",
   "metadata": {},
   "source": [
    "## Arquitectura General\n",
    "\n",
    "\n",
    "Es hora de dise√±ar un algoritmo sencillo para distinguir las im√°genes de gatos de las que no lo son..\n",
    "\n",
    "**Expresiones matematicas que debes tener en cuenta**:\n",
    "\n",
    "Para un ejemplo $x^{(i)}$, donde i representa el indice de dicho ejemplo:\n",
    "\n",
    "\n",
    "$$z^{(i)} = w^T x^{(i)} + b \\tag{1}$$\n",
    "$$\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\\tag{2}$$ \n",
    "$$ \\mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(a^{(i)}) - (1-y^{(i)} )  \\log(1-a^{(i)})\\tag{3}$$\n",
    "\n",
    "\n",
    "El costo es calculado por la suma sobre el error o perdida de todos los ejemplos:\n",
    "\n",
    "$$ C = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})\\tag{6}$$\n",
    "\n",
    "**Aspectos Claves**:\n",
    "    \n",
    "En este ejercicio, realizar√°s los siguientes pasos: \n",
    "\n",
    "- Inicializar los par√°metros del modelo.\n",
    "- Aprender los par√°metros del modelo minimizando el costo **C**.  \n",
    "- Utilizar los par√°metros aprendidos para hacer predicciones (en el conjunto de pruebas).\n",
    "- Analizar los resultados y concluir\n",
    "\n",
    "\n",
    "Los principales pasos para construir una red neuronal son:\n",
    "\n",
    "1. Definir la estructura del modelo (como el n√∫mero de caracter√≠sticas de entrada) \n",
    "2. Inicializar los par√°metros del modelo\n",
    "3. Bucle:\n",
    "    - Calcular la p√©rdida de corriente (propagaci√≥n hacia delante)\n",
    "    - Calcular el gradiente actual (propagaci√≥n hacia atr√°s)\n",
    "    - Actualizar los par√°metros (descenso de gradiente)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fffcce",
   "metadata": {},
   "source": [
    "**Ejercicio**: Implementa una funcion `sigmoid()`, que reciba como parametro un escalar o un arreglo numpy. Como has visto, necesitas calcular $sigmoide( w^T x + b) = \\frac{1}{1 + e^{-(w^T x + b)}}$ para hacer predicciones. Utilice \n",
    "```python\n",
    "np.exp()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a4f6a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### PONGA SU CODIGO AQUI ###\n",
    "    s = 1./(1+np.exp(-z))\n",
    "    ### FIN DE SU CODIGO\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2be30357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid([0, 2]) = [0.5        0.88079708]\n"
     ]
    }
   ],
   "source": [
    "print (\"sigmoid([0, 2]) = \" + str(sigmoid(np.array([0,2]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd56d30",
   "metadata": {},
   "source": [
    "**Salida esperada**\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>sigmoid([0, 2])</td>\n",
    "    <td> [ 0.5         0.88079708]</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a69374",
   "metadata": {},
   "source": [
    "### Initializing parameters\n",
    "\n",
    "**Ejercicio:** Implementa la inicializaci√≥n de los par√°metros en la celda de abajo. Tienes que inicializar w como un vector de ceros. Si no sabes qu√© funci√≥n de numpy usar, busca np.zeros() en la documentaci√≥n de la biblioteca Numpy.\n",
    "\n",
    "Aqui vamos a inicializar en 0, porque a pesar de que lo usual es inicializar random como quedamos en la conferencia, Nos evitaremos el no determinismo que acarrea ejecutar una celda varias veces, teninedo en cuenta que la funcion de coste es concava.\n",
    "\n",
    "**Lo que pasaba ayer que np.random.seed() no permitia obtener el mismo resultado cada vez, es que el kernel de python sobre el cual corre jupyter no para caundo se ejecuta una celda, si no que sigue ejecutandose, esto permite que podamos acceder a variables de una celda desde otra, por lo que correr x = np.random.randn() varias veces seria equivalente a generar tantos numeros aleatorios como las veces que corramos la celda. Puedes correr en un terminal si estas en linux la siguiente linea de comando tantas veces como quieras y en ese caso si obtendras el mismo resultado, ya que el codigo de python corre y luego se detiene:**\n",
    "\n",
    "```bash\n",
    "python -c 'import numpy as np; np.random.seed(3);print(np.random.randn())'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c05dc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    Esta funcion crea un vector de ceros de dimension (dim, 1) para w e inicializa b en 0.\n",
    "    \n",
    "    Argument:\n",
    "    dim -- el tama√±o del vector w (o numero de parametros en nuestro caso, recuerden que w <w1,w2,w3>)\n",
    "    \n",
    "    Returns:\n",
    "    w -- un 0-vector de la forma (dim, 1)\n",
    "    b -- un escalar (correspondiente al termino de sesgo)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (‚âà 1 line of code)\n",
    "    w = np.zeros((dim,1))\n",
    "    b = 0\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    assert(w.shape == (dim, 1))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb8f813b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [[0.]\n",
      " [0.]]\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "dim = 2\n",
    "w, b = initialize_with_zeros(dim)\n",
    "print (\"w = \" + str(w))\n",
    "print (\"b = \" + str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be18f4df",
   "metadata": {},
   "source": [
    "**Salida Esperada**: \n",
    "‚Äã\n",
    "‚Äã\n",
    "<table style=\"width:15%\">\n",
    "    <tr>\n",
    "        <td>  w   </td>\n",
    "        <td> [[ 0.]\n",
    "              [ 0.]] </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>   b  </td>\n",
    "        <td> 0 </td>\n",
    "    </tr>\n",
    "</table>\n",
    "‚Äã\n",
    "Para la entrada que tenemos, w tendra la forma (num_px $\\times$ num_px $\\times$ 3, 1), es decir nuestra neurona, o  nuestra funcion de aproximacion tendra num_px $\\times$ num_px $\\times$ 3 parametros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a6d606",
   "metadata": {},
   "source": [
    "### Forward and Backward propagation\n",
    "\n",
    "Ahora que todos los parametros estan inicializados pordemos hacer la propagacion hacia adelante y hacia atras para el aprendizaje de los parametros.\n",
    "\n",
    "**Hints**:\n",
    "\n",
    "Primero recordar que la notacion $X^{(i)}$ se refiere al $i-esimo$ ejemplo de la imagen en su forma plana, que calculamos usando la funcion reshape.\n",
    "\n",
    "Forward Propagation:\n",
    "- Tenemos X\n",
    "- Calculamos a $A = \\sigma(w^T X^{(i)} + b) = (a^{(1)}, a^{(2)}, ..., a^{(m-1)}, a^{(m)})$\n",
    "- Calculamos la funcion de costo como: $J = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})$\n",
    "\n",
    "Aqui hay dos formulas que usaremos: \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{8}$$\n",
    "\n",
    "y \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w_{k}} = \\frac{1}{m} \\sum_{i=1}^m x_{k}^{(i)}(a^{(i)}-y^{(i)})\\tag{9}$$\n",
    "\n",
    "Fijate que estamos hablando de la componente $k-esima$ del vector de entrada $X^{(i)}$ y de los parametros $w$. Lo cual en forma matricial puede ser expresado como\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T\\tag{9.1}$$\n",
    "\n",
    "Numpy para sus arreglos tiene implementado lo que es conocido como el broadcasting y es ideal para el uso de vectorizacion.\n",
    "- El brodacasting no es mas que la extension que realiza numpy a efectuar operaciones entre arreglos numpy en sobre eje, siempre que el resto de los ejes (dimesiones) matchee, por ejemplo:\n",
    "\n",
    "$$\\begin{bmatrix} a_{1} \\\\ a_{2} \\\\ a_{3}  \\end{bmatrix} + [b] \\implies \\begin{bmatrix} a_{1} \\\\ a_{2} \\\\ a_{3}  \\end{bmatrix} + \\begin{bmatrix} b \\\\ b \\\\ b  \\end{bmatrix} = \\begin{bmatrix} a_{1}+b \\\\ a_{2}+b \\\\ a_{3} +b \\end{bmatrix}$$\n",
    "\n",
    "- La vectoriazacion no es mas que tratar la operacion de producto de varios elementos y su suma como una operacion de productos de matrices. Esto es fundamental para la paralelizacion de las operaciones de las cuales nnumpy se aprovecha. Por ejemplo:\n",
    "\n",
    "$$w_{1}x_{1}+w_{2}x_{2} + w_{3}x_{3} + w_{4}x_{4} = \\begin{bmatrix} w_{1} \\\\ w_{2} \\\\ w_{3}  \\end{bmatrix}^{T}*\\begin{bmatrix} x_{1} \\\\ x_{2} \\\\ x_{3}  \\end{bmatrix} = \\begin{bmatrix} w_{1}&w_{2}&w_{3}  \\end{bmatrix}\\begin{bmatrix} x_{1} \\\\ x_{2} \\\\ x_{3}  \\end{bmatrix} = w^{T}*X$$\n",
    "\n",
    "     En el caso que nos ocupa, X para cada fila contiene un ejemplo, una manera simplificado de esbozar este ejemplo, dado \n",
    "\n",
    "\n",
    "$$X = \\begin{bmatrix} x_{1}^{(1)} & x_{1}^{(2)} & x_{1}^{(3)} \\\\ x_{2}^{(1)} & x_{2}^{(2)} & x_{2}^{(3)} \\\\ x_{3}^{(1)} & x_{3}^{(1)} & x_{3}^{(1)} \\end{bmatrix}$$\n",
    "\n",
    "\n",
    "    Luego:\n",
    "\n",
    "$$w^{T}*X = \\begin{bmatrix} w_{1}&w_{2}&w_{3}  \\end{bmatrix}\\begin{bmatrix} x_{1}^{(1)} & x_{1}^{(2)} & x_{1}^{(3)} \\\\ x_{2}^{(1)} & x_{2}^{(2)} & x_{2}^{(3)} \\\\ x_{3}^{(1)} & x_{3}^{(1)} & x_{3}^{(1)} \\end{bmatrix} = \\begin{bmatrix} a^{(1)} & a^{(2)} & a^{(3)}  \\end{bmatrix}$$\n",
    "\n",
    "Por lo que seria conveniente que nuestro arrego de datos de entrada tuvieran la forma $(num_px * num_px * 3,~ numero~de~ejemplos)$ y para calcular el gradiente el vector de la etiqueta de los ejemplos tenga la forma $(1,~ numero~de~ejemplos)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba38ed5",
   "metadata": {},
   "source": [
    "**Ejercicio:** emplee la propiedad transpuesta de los arreglos numpy para que los datos de entrada de test y train tengan la forma $(num_px * num_px * 3,~ numero~de~ejemplo)$\n",
    "\n",
    "```python\n",
    "X.T # devuelve la transpuesta de la matriz T\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec7b6a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x_flatten shape: (12288, 209)\n",
      "train_set_y shape: (1, 209)\n",
      "test_set_x_flatten shape: (12288, 50)\n",
      "test_set_y shape: (1, 50)\n"
     ]
    }
   ],
   "source": [
    "### PROGRAME AQUI ###\n",
    "train_set_x_flatten = train_set_x_flatten.T\n",
    "train_set_y = train_set_y.T\n",
    "test_set_x_flatten = test_set_x_flatten.T\n",
    "test_set_y = test_set_y.T\n",
    "### FIN DE SU CODIGO ###\n",
    "\n",
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9fc206",
   "metadata": {},
   "source": [
    "**Salida Esperada**: \n",
    "\n",
    "<table style=\"width:35%\">\n",
    "  <tr>\n",
    "    <td>train_set_x_flatten shape</td>\n",
    "    <td> (12288, 209)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>train_set_y shape</td>\n",
    "    <td>(1, 209)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>test_set_x_flatten shape</td>\n",
    "    <td>(12288, 50)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>test_set_y shape</td>\n",
    "    <td>(1, 50)</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca10770b",
   "metadata": {},
   "source": [
    "**Ejercicio:** Implemente la funcion `propagate()` que calcula la funcion de costo y sus gradientes, haciendo uso del broadcasting y la vectorizacion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9642c2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Implementa la funcion de costo y sus gradientes para la propagacion explicada arriba\n",
    "\n",
    "    Arguments:\n",
    "    w -- pesos de los parametros, un arreglo numpy de la forma (num_px * num_px * 3, 1)\n",
    "    b -- bias, un scalar\n",
    "    X -- conjunto de datos (num_px * num_px * 3, numero de ejemplos)\n",
    "    Y -- vector de etiquetas (conteniendo 0 si non-cat, 1 si cat) de la forma (1, numero de ejemplos)\n",
    "\n",
    "    Return:\n",
    "    cost -- el opuesto de la probabilidad log para la regresion logisitca\n",
    "    dw -- gradiente de la perdida con respecto a w, por tanto tine la misma shape de w\n",
    "    db -- gradiente de la perdida con respecto a b, por tanto tine la misma shape de b\n",
    "    \n",
    "    Tips:\n",
    "    - np.log() calcula logaritmo de escalar o arreglo numpy, np.dot() calcula el producto matricial de dos arreglos numpy\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # FORWARD PROPAGATION (FROM X TO COST)\n",
    "    ### PROGRAMA AQUI ###\n",
    "    A = sigmoid(np.dot(w.T,X) +b)                                   # compute activation\n",
    "    #cost = -(np.dot(Y, np.log(A.T)) + np.dot(1. - Y, np.log(1. - A.T)))/m\n",
    "    cost = 0\n",
    "    for i in range(m):\n",
    "        cost = cost+ (Y[0][i])*np.log(A[0][i]) + (1. - Y[0][i])*np.log(1. - A[0][i])\n",
    "\n",
    "    cost = -(cost)/m\n",
    "    # compute cost\n",
    "    ### FIN DEL CODE ###\n",
    "    \n",
    "    # BACKWARD PROPAGATION (TO FIND GRAD)\n",
    "    ### PROGRAMA AQUI ### \n",
    "    db = A - Y\n",
    "    dw = (np.dot(X,db.T))/m\n",
    "    db = np.sum(db)/m\n",
    "    ### FIN DEL CODE ###\n",
    "\n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d8a589b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw = [[0.99845601]\n",
      " [2.39507239]]\n",
      "db = 0.001455578136784208\n",
      "cost = 5.801545319394553\n"
     ]
    }
   ],
   "source": [
    "w, b, X, Y = np.array([[1.],[2.]]), 2., np.array([[1.,2.,-1.],[3.,4.,-3.2]]), np.array([[1,0,1]])\n",
    "grads, cost = propagate(w, b, X, Y)\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print (\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a66645",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table style=\"width:50%\">\n",
    "    <tr>\n",
    "        <td>  dw  </td>\n",
    "      <td> [[ 0.99845601]\n",
    "     [ 2.39507239]]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  db  </td>\n",
    "        <td> 0.00145557813678 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  cost </td>\n",
    "        <td> 5.801545319394553 </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cc9242",
   "metadata": {},
   "source": [
    "### Optimizacion\n",
    "\n",
    "- Has inicializado tus par√°metros.\n",
    "- Tambi√©n eres capaz de calcular una funci√≥n de coste y su gradiente.\n",
    "- Ahora, quieres actualizar los par√°metros utilizando el descenso de gradiente.\n",
    "\n",
    "**Ejercicio:** Escriba la funci√≥n de optimizaci√≥n. El objetivo es aprender $w$ y $b$ minimizando la funci√≥n de coste $C$. Para un par√°metro $\\theta$, la regla de actualizaci√≥n es $ \\theta = \\theta - \\alpha \\text{ } d\\theta$, donde $\\alpha$ es la tasa de aprendizaje (learning rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18897598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    Esta funci√≥n optimiza w y b ejecutando un algoritmo de descenso de gradiente\n",
    "    \n",
    "    Arguments:\n",
    "    w -- pesos, un array numpy de tama√±o (num_px * num_px * 3, 1)\n",
    "    b -- bias, un escalar\n",
    "    X -- datos de forma (num_px * num_px * 3, n√∫mero de ejemplos)\n",
    "    Y -- vector de etiquetas (que contiene 0 si no es gato, 1 si es gato), de forma (n√∫mero de ejemplos, 1)\n",
    "    num_iterations -- n√∫mero de iteraciones del bucle de optimizaci√≥n\n",
    "    learning_rate -- tasa de aprendizaje de la regla de actualizaci√≥n del descenso de gradiente\n",
    "    print_cost -- bool que en Verdadero permite imprimir la p√©rdida cada 100 iteraciones del algoritmo del descenso del graiente\n",
    "    \n",
    "    Return:\n",
    "    params -- diccionario que contiene los pesos w y el sesgo b\n",
    "    grads -- diccionario que contiene los gradientes de los pesos y el bias con respecto a la funci√≥n de coste\n",
    "    costs -- lista de todos los costes calculados durante la optimizaci√≥n, que se utilizar√° para trazar la curva de aprendizaje.\n",
    "    \n",
    "    Consejos:\n",
    "    B√°sicamente necesitas escribir dos pasos e iterar a trav√©s de ellos:\n",
    "        1) Calcular el coste y el gradiente para los par√°metros actuales. Use propagate().\n",
    "        2) Actualizar los par√°metros utilizando la regla de descenso de gradiente para w y b.\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        \n",
    "        # Calculo del Costo y el gradiente\n",
    "        ### PROGRAMA AQUI ### \n",
    "        grads, cost = propagate(w,b,X,Y)\n",
    "        ### FIN DEL CODIGO ###\n",
    "        \n",
    "        # Obten las derivadas de grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # Regla de actualizacion del descenso del gradiente\n",
    "        ### PROGRAMA AQUI ### \n",
    "        w = w - dw*learning_rate\n",
    "        b = b - db*learning_rate\n",
    "        ### FIN DEL CODIGO ###\n",
    "        \n",
    "        # guarda los costos\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        # Imprimir el costo cada 100 iteraciones\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "420a4632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [[0.19033591]\n",
      " [0.12259159]]\n",
      "b = 1.9253598300845747\n",
      "dw = [[0.67752042]\n",
      " [1.41625495]]\n",
      "db = 0.21919450454067657\n",
      "[[1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "params, grads, costs = optimize(w, b, X, Y, num_iterations= 100, learning_rate = 0.009, print_cost = False)\n",
    "\n",
    "print (\"w = \" + str(params[\"w\"]))\n",
    "print (\"b = \" + str(params[\"b\"]))\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print (Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bdb6e9",
   "metadata": {},
   "source": [
    "**Salida Esperada**: \n",
    "\n",
    "<table >\n",
    "<tr>\n",
    "<td> w </td>\n",
    "<td>[[ 0.19033591]\n",
    "[ 0.12259159]] </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td> b </td>\n",
    "<td> 1.92535983008 </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td> dw </td>\n",
    "<td> [[ 0.67752042]\n",
    "[ 1.41625495]] </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td> **db** </td>\n",
    "<td> 0.219194504541 </td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923dbb2c",
   "metadata": {},
   "source": [
    "\n",
    "**Exercise:** The previous function will output the learned w and b. We are able to use w and b to predict the labels for a dataset X. Implement the `predict()` function. There are two steps to computing predictions:\n",
    "\n",
    "1. Calculate $\\hat{Y} = A = \\sigma(w^T X + b)$\n",
    "\n",
    "2. Convert the entries of a into 0 (if activation <= 0.5) or 1 (if activation > 0.5), stores the predictions in a vector `Y_prediction`. If you wish, you can use an `if`/`else` statement in a `for` loop (though there is also a way to vectorize this). \n",
    "\n",
    "**Ejercicio:**\n",
    "\n",
    "La funci√≥n anterior dar√° como resultado los valores aprendidos w y b. Podemos utilizar w y b para predecir las etiquetas de un conjunto de datos X. Implementa la funci√≥n `predict()`.\n",
    "\n",
    "Hay dos pasos para calcular las predicciones:\n",
    "\n",
    "1. Calcular $\\hat{Y} = A = \\sigma(w^T X + b)$\n",
    "\n",
    "2. Convertir los valores de a en 0 (si la activaci√≥n <= 0,5) o 1 (si la activaci√≥n > 0,5). Ya que recuerda que un valor de probabilidad, almacena las predicciones en un vector `Y_predicci√≥n`. Si lo deseas, puedes utilizar una sentencia `if`/`else` en un bucle `for` (aunque tambi√©n hay una forma de vectorizar esto). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48ec9d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    '''\n",
    "    \n",
    "    Predecir si la etiqueta es 0 o 1 utilizando los par√°metros de regresi√≥n log√≠stica aprendidos (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- pesos, una matriz numpy de tama√±o (num_px * num_px * 3, 1)\n",
    "    b -- sesgo, un escalar\n",
    "    X -- datos de tama√±o (num_px * num_px * 3, n√∫mero de ejemplos)\n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- un arreglo numpy (vector) que contiene todas las predicciones (0/1) para los ejemplos en X\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    # calcular el vector \"A\" que predice las probabilidades de que haya un gato en la imagen\n",
    "    ### PROGRAMA AQUI ### \n",
    "    A= sigmoid(np.dot(w.T,X) + b )\n",
    "    ### FIN DEL CODE ###\n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        \n",
    "        # Convertir las probabilidades A[0,i] en predicciones reales p[0,i]\n",
    "        ### PROGRAMA AQUI ### \n",
    "        if A[0][i] >0.5:\n",
    "            Y_prediction[0][i] = 1\n",
    "        ### FIN DEL CODE ###\n",
    "    \n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08d4acc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions = [[1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "w = np.array([[0.1124579],[0.23106775]])\n",
    "b = -0.3\n",
    "X = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\n",
    "print (\"predictions = \" + str(predict(w, b, X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4f2bbb",
   "metadata": {},
   "source": [
    "**Salida esperada**: \n",
    "\n",
    "<table style=\"width:30%\">\n",
    "    <tr>\n",
    "         <td>\n",
    "             predictions\n",
    "         </td>\n",
    "          <td>\n",
    "            [[ 1.  1.  0.]]\n",
    "         </td>  \n",
    "   </tr>\n",
    "\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae9e69a",
   "metadata": {},
   "source": [
    "\n",
    "### Hasta el momento que deber recordar:\n",
    "\n",
    "\n",
    "Has implementado varias funciones que:\n",
    "    \n",
    "- Inicializan (w,b)\n",
    "\n",
    "- Optimizan la p√©rdida iterativamente para aprender los par√°metros (w,b):\n",
    "    - calcular el coste y su gradiente \n",
    "    - actualizar los par√°metros mediante el descenso de gradiente\n",
    "- Utilizar los par√°metros aprendidos (w,b) para predecir las etiquetas de un conjunto dado de ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b636122",
   "metadata": {},
   "source": [
    "## Uniendo las funcinoes en nuestro modelo ##\n",
    "\n",
    "\n",
    "Ahora ver√°s c√≥mo est√° estructurado el modelo global al juntar todos los bloques (funciones implementadas en las partes anteriores), en el orden correcto.\n",
    "\n",
    "**Ejercicio:**\n",
    "\n",
    "Implementar la funci√≥n del modelo. Utilice la siguiente notaci√≥n:\n",
    "- Y_prediction_test para tus predicciones en el conjunto de prueba\n",
    "- Y_prediction_train para tus predicciones en el conjunto de entrenamiento\n",
    "- w, costs, grads para las salidas de optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36c0a6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n",
    "    \"\"\"\n",
    "    \n",
    "    Construye el modelo de regresi√≥n log√≠stica llamando a las funci√≥nes que has implementado previamente\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- conjunto de entrenamiento representado por una matriz numpy de forma (num_px * num_px * 3, m_train)\n",
    "    Y_train -- etiquetas de entrenamiento representadas por un arreglo numpy (vector) de forma (1, m_train)\n",
    "    X_test -- conjunto de pruebas representado por un arreglo  numpy de forma (num_px * num_px * 3, m_test)\n",
    "    Y_test -- etiquetas de prueba representadas por un arreglo  numpy (vector) de forma (1, m_test)\n",
    "    num_iterations -- hiperpar√°metro que representa el n√∫mero de iteraciones para optimizar los par√°metros\n",
    "    learning_rate -- hiperpar√°metro que representa la tasa de aprendizaje utilizada en la regla de actualizaci√≥n de optimize()\n",
    "    print_cost -- Se establece en true para imprimir el coste cada 100 iteraciones\n",
    "    \n",
    "    Returns:\n",
    "    d -- diccionario que contiene informaci√≥n sobre el modelo.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### PROGRAMA AQUI ###\n",
    "    \n",
    "    # Inicializa los parametros con 0\n",
    "    w, b = initialize_with_zeros(12288)\n",
    "    print(str(w.shape))\n",
    "    print(str(X_train.shape))\n",
    "\n",
    "    # Gradient descent \n",
    "    parameters, grads, costs = optimize(w,b,X_train,Y_train,num_iterations,learning_rate)\n",
    "    \n",
    "    # Obten los parametros w y b del diccionario \"parameters\"\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    # Predecir ejemplos del conjunto de test/train\n",
    "    print(\"w:\" + str(w.shape))\n",
    "    Y_prediction_test = predict( w , b , X_test )\n",
    "    Y_prediction_train = predict( w , b , X_train )\n",
    "\n",
    "    ### FIN DEL CODE ###\n",
    "\n",
    "    # Imprime Error del train/test\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95883521",
   "metadata": {},
   "source": [
    "## Con la siguiente celda entrenaremos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edcb9414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12288, 1)\n",
      "(12288, 209)\n",
      "w:(12288, 1)\n",
      "train accuracy: 99.04306220095694 %\n",
      "test accuracy: 70.0 %\n"
     ]
    }
   ],
   "source": [
    "history = model(train_set_x_flatten, train_set_y, test_set_x_flatten, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4e1473",
   "metadata": {},
   "source": [
    "**Comentario:**\n",
    "\n",
    "La precisi√≥n del entrenamiento se acerca al 100%. Esto es una buena comprobaci√≥n de cordura: su modelo est√° funcionando y tiene suficiente capacidad para ajustarse a los datos de entrenamiento. El error de prueba es del 70%. En realidad no est√° mal para este sencillo modelo, dado el peque√±o conjunto de datos que utilizamos y que la regresi√≥n log√≠stica es un clasificador lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92a5eaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curve (with costs)\n",
    "costs = np.squeeze(history['costs'])\n",
    "plt.plot(costs)\n",
    "plt.ylabel('Costo')\n",
    "plt.xlabel('Iteraciones (x100)')\n",
    "plt.title(\"Learning rate =\" + str(history[\"learning_rate\"]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
